{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較使用 l1, l1_l2 及不同比例下的訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], l1_ratio=1e-4):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1), \n",
    "                                   kernel_regularizer=l1(l1_ratio))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=l1(l1_ratio))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95\n",
    "L1_EXP = [1e-2, 1e-4, 1e-8, 1e-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Regulizer = 0.010000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 198.4165 - acc: 0.2550 - val_loss: 41.1045 - val_acc: 0.2990\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 19.0886 - acc: 0.1209 - val_loss: 7.2565 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 4.1026 - acc: 0.0980 - val_loss: 2.6560 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 2.4875 - acc: 0.0991 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 2.4626 - acc: 0.0966 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 2.4626 - acc: 0.0962 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 2.4626 - acc: 0.1000 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 2.4626 - acc: 0.0997 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 2.4626 - acc: 0.0995 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 2.4626 - acc: 0.0967 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 2.4626 - acc: 0.0993 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 2.4626 - acc: 0.0965 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 2.4626 - acc: 0.0977 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Experiment with Regulizer = 0.000100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 17s 343us/step - loss: 6.0265 - acc: 0.2660 - val_loss: 5.8288 - val_acc: 0.3387\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 5.7309 - acc: 0.3611 - val_loss: 5.6457 - val_acc: 0.3795\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 5.5795 - acc: 0.3934 - val_loss: 5.5186 - val_acc: 0.4008\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 16s 320us/step - loss: 5.4560 - acc: 0.4139 - val_loss: 5.3995 - val_acc: 0.4188\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 16s 322us/step - loss: 5.3464 - acc: 0.4311 - val_loss: 5.2979 - val_acc: 0.4361\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 5.2414 - acc: 0.4470 - val_loss: 5.2076 - val_acc: 0.4391\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 5.1465 - acc: 0.4557 - val_loss: 5.1186 - val_acc: 0.4493\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 5.0568 - acc: 0.4650 - val_loss: 5.0493 - val_acc: 0.4519\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 97s 2ms/step - loss: 4.9683 - acc: 0.4743 - val_loss: 4.9597 - val_acc: 0.4577\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 24s 489us/step - loss: 4.8841 - acc: 0.4835 - val_loss: 4.8850 - val_acc: 0.4691\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 4.8022 - acc: 0.4906 - val_loss: 4.7908 - val_acc: 0.4818\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 255s 5ms/step - loss: 4.7229 - acc: 0.4978 - val_loss: 4.7295 - val_acc: 0.4816\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 4.6445 - acc: 0.5072 - val_loss: 4.6523 - val_acc: 0.4858\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 4.5667 - acc: 0.5117 - val_loss: 4.5984 - val_acc: 0.4851\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 4.4919 - acc: 0.5207 - val_loss: 4.5280 - val_acc: 0.4886\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 4.4228 - acc: 0.5240 - val_loss: 4.4603 - val_acc: 0.4978\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 205s 4ms/step - loss: 4.3506 - acc: 0.5292 - val_loss: 4.4090 - val_acc: 0.4896\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 24s 489us/step - loss: 4.2798 - acc: 0.5333 - val_loss: 4.3501 - val_acc: 0.5007\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 4.2141 - acc: 0.5399 - val_loss: 4.2651 - val_acc: 0.5033\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 206s 4ms/step - loss: 4.1457 - acc: 0.5428 - val_loss: 4.2159 - val_acc: 0.5003\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 25s 491us/step - loss: 4.0799 - acc: 0.5478 - val_loss: 4.1709 - val_acc: 0.4964\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 4.0168 - acc: 0.5512 - val_loss: 4.1091 - val_acc: 0.5012\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 206s 4ms/step - loss: 3.9515 - acc: 0.5574 - val_loss: 4.0313 - val_acc: 0.5134\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 25s 494us/step - loss: 3.8918 - acc: 0.5600 - val_loss: 4.0136 - val_acc: 0.5049\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 3.8286 - acc: 0.5631 - val_loss: 3.9920 - val_acc: 0.4994\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 345s 7ms/step - loss: 3.7717 - acc: 0.5652 - val_loss: 3.8913 - val_acc: 0.5108\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 25s 494us/step - loss: 3.7124 - acc: 0.5719 - val_loss: 3.8150 - val_acc: 0.5194\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 3.6554 - acc: 0.5741 - val_loss: 3.7772 - val_acc: 0.5175\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 3.5953 - acc: 0.5792 - val_loss: 3.7225 - val_acc: 0.5212\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 3.5402 - acc: 0.5827 - val_loss: 3.7594 - val_acc: 0.4998\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 15s 301us/step - loss: 3.4904 - acc: 0.5844 - val_loss: 3.6401 - val_acc: 0.5275\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 216s 4ms/step - loss: 3.4349 - acc: 0.5873 - val_loss: 3.6373 - val_acc: 0.5101\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 16s 322us/step - loss: 3.3782 - acc: 0.5891 - val_loss: 3.5559 - val_acc: 0.5220\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 205s 4ms/step - loss: 3.3300 - acc: 0.5942 - val_loss: 3.5855 - val_acc: 0.5017\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 3.2798 - acc: 0.5972 - val_loss: 3.4258 - val_acc: 0.5365\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 3.2295 - acc: 0.6015 - val_loss: 3.4350 - val_acc: 0.5210\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 206s 4ms/step - loss: 3.1814 - acc: 0.6019 - val_loss: 3.3767 - val_acc: 0.5241\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 25s 497us/step - loss: 3.1342 - acc: 0.6038 - val_loss: 3.3375 - val_acc: 0.5238\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 3.0895 - acc: 0.6062 - val_loss: 3.3394 - val_acc: 0.5098\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 206s 4ms/step - loss: 3.0404 - acc: 0.6082 - val_loss: 3.2502 - val_acc: 0.5230\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 2.9967 - acc: 0.6121 - val_loss: 3.1967 - val_acc: 0.5355\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 15s 305us/step - loss: 2.9514 - acc: 0.6156 - val_loss: 3.3232 - val_acc: 0.4912\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 2.9176 - acc: 0.6139 - val_loss: 3.1146 - val_acc: 0.5351\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 16s 323us/step - loss: 2.8694 - acc: 0.6175 - val_loss: 3.0940 - val_acc: 0.5302\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 205s 4ms/step - loss: 2.8233 - acc: 0.6214 - val_loss: 3.1191 - val_acc: 0.5102\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 26s 515us/step - loss: 2.7839 - acc: 0.6226 - val_loss: 3.1053 - val_acc: 0.5070\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 7215s 144ms/step - loss: 2.7519 - acc: 0.6213 - val_loss: 3.0650 - val_acc: 0.5089\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 7217s 144ms/step - loss: 2.7132 - acc: 0.6240 - val_loss: 2.9579 - val_acc: 0.5298\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 14418s 288ms/step - loss: 2.6692 - acc: 0.6288 - val_loss: 2.9094 - val_acc: 0.5373\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 14395s 288ms/step - loss: 2.6432 - acc: 0.6261 - val_loss: 2.9934 - val_acc: 0.5030\n",
      "Experiment with Regulizer = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 227s 5ms/step - loss: 2.0234 - acc: 0.2743 - val_loss: 1.8625 - val_acc: 0.3468\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 1.8071 - acc: 0.3678 - val_loss: 1.7563 - val_acc: 0.3878\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.7242 - acc: 0.3977 - val_loss: 1.6960 - val_acc: 0.4098\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 1.6669 - acc: 0.4185 - val_loss: 1.6496 - val_acc: 0.4240\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 1.6212 - acc: 0.4332 - val_loss: 1.6200 - val_acc: 0.4343\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 1.5832 - acc: 0.4449 - val_loss: 1.5753 - val_acc: 0.4453\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 18s 363us/step - loss: 1.5485 - acc: 0.4572 - val_loss: 1.5556 - val_acc: 0.4594\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 1.5176 - acc: 0.4700 - val_loss: 1.5498 - val_acc: 0.4514\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 1.4896 - acc: 0.4779 - val_loss: 1.5127 - val_acc: 0.4593\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 1.4644 - acc: 0.4864 - val_loss: 1.4958 - val_acc: 0.4671\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 18s 365us/step - loss: 1.4410 - acc: 0.4925 - val_loss: 1.4756 - val_acc: 0.4755\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.4175 - acc: 0.5016 - val_loss: 1.4552 - val_acc: 0.4786\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 1.3948 - acc: 0.5082 - val_loss: 1.4646 - val_acc: 0.4746\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 1.3744 - acc: 0.5165 - val_loss: 1.4674 - val_acc: 0.4759\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 18s 360us/step - loss: 1.3565 - acc: 0.5241 - val_loss: 1.4376 - val_acc: 0.4896\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 1.3377 - acc: 0.5290 - val_loss: 1.4363 - val_acc: 0.4903\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 1.3191 - acc: 0.5357 - val_loss: 1.4018 - val_acc: 0.5015\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 19s 376us/step - loss: 1.3014 - acc: 0.5415 - val_loss: 1.4075 - val_acc: 0.5001\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 1.2849 - acc: 0.5465 - val_loss: 1.3920 - val_acc: 0.4969\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 1.2691 - acc: 0.5517 - val_loss: 1.3754 - val_acc: 0.5170\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 22s 439us/step - loss: 1.2540 - acc: 0.5581 - val_loss: 1.4215 - val_acc: 0.4966\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 1.2383 - acc: 0.5647 - val_loss: 1.3701 - val_acc: 0.5160\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 1.2223 - acc: 0.5681 - val_loss: 1.3796 - val_acc: 0.5105\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 1.2102 - acc: 0.5734 - val_loss: 1.3834 - val_acc: 0.5114\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 1.1930 - acc: 0.5815 - val_loss: 1.3534 - val_acc: 0.5197\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 18s 361us/step - loss: 1.1799 - acc: 0.5833 - val_loss: 1.3590 - val_acc: 0.5203\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 1.1691 - acc: 0.5878 - val_loss: 1.3569 - val_acc: 0.5191\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 18s 366us/step - loss: 1.1550 - acc: 0.5938 - val_loss: 1.3546 - val_acc: 0.5286\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 18s 362us/step - loss: 1.1396 - acc: 0.5980 - val_loss: 1.4213 - val_acc: 0.4945\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 18s 362us/step - loss: 1.1305 - acc: 0.6013 - val_loss: 1.3351 - val_acc: 0.5283\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 1.1123 - acc: 0.6090 - val_loss: 1.3919 - val_acc: 0.5150\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 1.1042 - acc: 0.6121 - val_loss: 1.4117 - val_acc: 0.5140\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 1.0886 - acc: 0.6186 - val_loss: 1.3903 - val_acc: 0.5124\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 1.0761 - acc: 0.6217 - val_loss: 1.3327 - val_acc: 0.5377\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 18s 369us/step - loss: 1.0667 - acc: 0.6255 - val_loss: 1.3938 - val_acc: 0.5226\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 1.0556 - acc: 0.6300 - val_loss: 1.4483 - val_acc: 0.5013\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 1.0419 - acc: 0.6343 - val_loss: 1.3484 - val_acc: 0.5277\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 1.0262 - acc: 0.6383 - val_loss: 1.4079 - val_acc: 0.5157\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 18s 361us/step - loss: 1.0146 - acc: 0.6447 - val_loss: 1.3700 - val_acc: 0.5220\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 18s 359us/step - loss: 1.0034 - acc: 0.6486 - val_loss: 1.3754 - val_acc: 0.5233\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 0.9889 - acc: 0.6541 - val_loss: 1.3472 - val_acc: 0.5330\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.9758 - acc: 0.6573 - val_loss: 1.3784 - val_acc: 0.5266\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.9681 - acc: 0.6590 - val_loss: 1.4801 - val_acc: 0.5016\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.9542 - acc: 0.6681 - val_loss: 1.3591 - val_acc: 0.5328\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.9474 - acc: 0.6676 - val_loss: 1.3742 - val_acc: 0.5351\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.9308 - acc: 0.6742 - val_loss: 1.3838 - val_acc: 0.5284\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 19s 376us/step - loss: 0.9158 - acc: 0.6781 - val_loss: 1.3681 - val_acc: 0.5326\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 0.9094 - acc: 0.6818 - val_loss: 1.4242 - val_acc: 0.5191\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.8979 - acc: 0.6857 - val_loss: 1.3777 - val_acc: 0.5300\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 0.8867 - acc: 0.6906 - val_loss: 1.4411 - val_acc: 0.5240\n",
      "Experiment with Regulizer = 0.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 22s 438us/step - loss: 2.0195 - acc: 0.2810 - val_loss: 1.8562 - val_acc: 0.3468\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 1.8051 - acc: 0.3703 - val_loss: 1.7545 - val_acc: 0.3857\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 19s 374us/step - loss: 1.7200 - acc: 0.3979 - val_loss: 1.6898 - val_acc: 0.4064\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 1.6596 - acc: 0.4196 - val_loss: 1.6471 - val_acc: 0.4195\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 1.6120 - acc: 0.4351 - val_loss: 1.6006 - val_acc: 0.4363\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 1.5737 - acc: 0.4490 - val_loss: 1.5698 - val_acc: 0.4489\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 1.5406 - acc: 0.4588 - val_loss: 1.5401 - val_acc: 0.4548\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 16s 323us/step - loss: 1.5095 - acc: 0.4702 - val_loss: 1.5215 - val_acc: 0.4629\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 1.4831 - acc: 0.4807 - val_loss: 1.5012 - val_acc: 0.4702\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 1.4563 - acc: 0.4901 - val_loss: 1.5096 - val_acc: 0.4703\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 1.4329 - acc: 0.4948 - val_loss: 1.4748 - val_acc: 0.4808\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 1.4120 - acc: 0.5021 - val_loss: 1.4573 - val_acc: 0.4815\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 1.3896 - acc: 0.5106 - val_loss: 1.4453 - val_acc: 0.4923\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 1.3710 - acc: 0.5183 - val_loss: 1.4433 - val_acc: 0.4921\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 1.3515 - acc: 0.5246 - val_loss: 1.4294 - val_acc: 0.4927\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 1.3328 - acc: 0.5291 - val_loss: 1.4364 - val_acc: 0.4951\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 1.3155 - acc: 0.5364 - val_loss: 1.4090 - val_acc: 0.5048\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 1.2981 - acc: 0.5424 - val_loss: 1.3971 - val_acc: 0.5042\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 1.2818 - acc: 0.5485 - val_loss: 1.3852 - val_acc: 0.5120\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 1.2656 - acc: 0.5539 - val_loss: 1.3793 - val_acc: 0.5147\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 18s 364us/step - loss: 1.2502 - acc: 0.5601 - val_loss: 1.3763 - val_acc: 0.5099\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 1.2373 - acc: 0.5637 - val_loss: 1.3560 - val_acc: 0.5229\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 1.2227 - acc: 0.5690 - val_loss: 1.3634 - val_acc: 0.5215\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 1.2079 - acc: 0.5734 - val_loss: 1.3672 - val_acc: 0.5167\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 1.1954 - acc: 0.5785 - val_loss: 1.3638 - val_acc: 0.5171\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 17s 345us/step - loss: 1.1812 - acc: 0.5832 - val_loss: 1.3475 - val_acc: 0.5268\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 1.1651 - acc: 0.5899 - val_loss: 1.3545 - val_acc: 0.5178\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 1.1522 - acc: 0.5919 - val_loss: 1.3643 - val_acc: 0.5250\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 1.1385 - acc: 0.5976 - val_loss: 1.3627 - val_acc: 0.5249\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 1.1268 - acc: 0.6036 - val_loss: 1.3623 - val_acc: 0.5239\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 1.1114 - acc: 0.6087 - val_loss: 1.3769 - val_acc: 0.5185\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 1.1005 - acc: 0.6120 - val_loss: 1.3451 - val_acc: 0.5244\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 1.0872 - acc: 0.6187 - val_loss: 1.3387 - val_acc: 0.5296\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 1.0735 - acc: 0.6216 - val_loss: 1.3299 - val_acc: 0.5301\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 1.0616 - acc: 0.6282 - val_loss: 1.4502 - val_acc: 0.5096\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 1.0490 - acc: 0.6320 - val_loss: 1.4493 - val_acc: 0.5015\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.0389 - acc: 0.6332 - val_loss: 1.4046 - val_acc: 0.5055\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.0239 - acc: 0.6393 - val_loss: 1.3431 - val_acc: 0.5259\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 1.0126 - acc: 0.6430 - val_loss: 1.4125 - val_acc: 0.5191\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 0.9991 - acc: 0.6469 - val_loss: 1.3782 - val_acc: 0.5274\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 0.9842 - acc: 0.6540 - val_loss: 1.3629 - val_acc: 0.5267\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 15s 305us/step - loss: 0.9792 - acc: 0.6546 - val_loss: 1.4427 - val_acc: 0.5068\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 0.9655 - acc: 0.6583 - val_loss: 1.5713 - val_acc: 0.4789\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 0.9538 - acc: 0.6652 - val_loss: 1.3883 - val_acc: 0.5254\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 0.9434 - acc: 0.6672 - val_loss: 1.6122 - val_acc: 0.4730\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 0.9262 - acc: 0.6764 - val_loss: 1.4041 - val_acc: 0.5253\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 0.9137 - acc: 0.6792 - val_loss: 1.4087 - val_acc: 0.5240\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 0.9039 - acc: 0.6820 - val_loss: 1.3969 - val_acc: 0.5263\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 15s 305us/step - loss: 0.8947 - acc: 0.6849 - val_loss: 1.3823 - val_acc: 0.5336\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 0.8819 - acc: 0.6901 - val_loss: 1.3434 - val_acc: 0.5448\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\n",
    "使用迴圈建立不同的帶不同 L1/L2 的模型並訓練\n",
    "\"\"\"\n",
    "for regulizer_ratio in L1_EXP:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with Regulizer = %.6f\" % (regulizer_ratio))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:], l1_ratio=regulizer_ratio)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-l2-%s\" % str(regulizer_ratio)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAF1CAYAAADFgbLVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xu8V3Wd7/HXRy4yoqYIjOlGIaEGkN1Wt6DHy3hD0RrMhkyzwoOmhp6TOhY2NY4K55g3xjre6mhKVpKXU9mMiUbZjE0WmKSCMSBibpxRLpoXREA/54/9Y/eDvWH/2Pe19+v5eOwHv7W+37XW9/fFh+/9Xb/F7xOZiSRJ6vp26OwBSJKkyhjakiQVhKEtSVJBGNqSJBWEoS1JUkEY2pIkFYShLUlSQRjaUkFExKMR8WpE7NjZY5HUOQxtqQAiYihwBJDAxA68bu+Oupak5hnaUjF8FngcuBOYvGlnRPxFRFwfES9ExJ8i4rGI+ItS2+ER8e8R8VpEvBgRZ5b2PxoRZ5ed48yIeKxsOyPi/IhYAiwp7ft66RyvR8QTEXFEWf9eEfH3EfFcRLxRah8SETdFxPXlbyIifhIRF7bHBEk9gaEtFcNnge+Vfk6IiL8s7b8OOAj4b8AA4EvAexGxD/BT4P8Ag4AaYMF2XO9jwDhgVGl7XukcA4DvA/dGRL9S28XA6cBJwK7AFGAtMAs4PSJ2AIiIgcCxwN3b88Yl/ZmhLXVxEXE4sC9wT2Y+ATwHfKoUhlOAL2Tmisx8NzP/PTPfAc4AfpaZd2fmhsxcnZnbE9pXZeaazHwbIDO/WzrHxsy8HtgR+FCp79nAVzNzcdb7fanvb4E/UR/UAKcBj2bmy62cEqnHMrSlrm8y8HBmriptf7+0byDQj/oQ39KQreyv1IvlGxHxdxHxbOkW/GvA+0rXb+5as4BPl15/GrirFWOSejwfMpG6sNLn06cCvSLiv0q7dwR2A94PrAP2A36/xaEvAmO3ctq3gJ3Ktvdsok9D+b/S59fTqF8xL8zM9yLiVSDKrrUf8EwT5/ku8ExEfBgYCfxoK2OSVAFX2lLX9jHgXeo/W64p/YwE/o36z7m/DcyMiL1KD4QdWvonYd8DjouIUyOid0TsERE1pXMuAD4eETtFxHDgrGbGsAuwEVgJ9I6Iy6j/7HqT24DpETEi6lVHxB4AmVlH/efhdwH3b7rdLqllDG2pa5sM3JGZf8zM/9r0A9xI/efWlwJPUx+Ma4CrgR0y84/UPxj2d6X9C4APl875T8B64GXqb19/r5kxzKH+obb/AF6gfnVffvt8JnAP8DDwOnA78Bdl7bOAMXhrXGq1yMzme0lSC0XEkdTfJh+ame919nikInOlLandREQf4AvAbQa21HqGtqR2EREjgdeof2Duhk4ejtQteHtckqSCcKUtSVJBGNqSJBVEl/tylYEDB+bQoUM7exiSJHWYJ554YlVmDmquX5cL7aFDhzJ//vzOHoYkSR0mIl6opJ+3xyVJKghDW5KkgjC0JUkqiC73mbYkqWU2bNhAXV0d69at6+yhaCv69etHVVUVffr0adHxhrYkdRN1dXXssssuDB06lIho/gB1qMxk9erV1NXVMWzYsBadw9vjktRNrFu3jj322MPA7qIigj322KNVd0IMbUnqRgzsrq21fz+GtiSpS1u+fDn7778/AI888ggHHXQQY8aM4aCDDuLnP/95k8esXr2ao48+mp133pkLLrigRdedNWsWI0aMYMSIEcyaNath/913382YMWOorq5mwoQJrFq1qkXnbwk/05YkFcbAgQP5yU9+wl577cUzzzzDCSecwIoVKxr169evH9OnT+eZZ57hmWee2e7rrFmzhiuuuIL58+cTERx00EFMnDiRXXbZhS984QssWrSIgQMH8qUvfYkbb7yRyy+/vA3eXfNcaUuS2tR3v/tdxo4dS01NDeeeey4vvPACI0aMYNWqVbz33nscccQRPPzwwyxfvpy/+qu/YvLkyVRXVzNp0iTWrl27zXMfcMAB7LXXXgCMHj2adevW8c477zTq179/fw4//HD69evXqO3hhx/m0EMP5cADD+QTn/gEb775ZqM+c+bMYfz48QwYMIDdd9+d8ePH89BDD5GZZCZvvfUWmcnrr7/eMJ6O4EpbkrqjCy+EBQva9pw1NXDDtkujP/vss/zgBz/gV7/6FX369GHq1Kn88pe/ZNq0aZx33nmMGzeOUaNGcfzxx7N8+XIWL17M7bffzmGHHcaUKVO4+eabueSSSyoazv33388BBxzAjjvuWPFbWLVqFTNmzOBnP/sZ/fv35+qrr2bmzJlcdtllm/VbsWIFQ4YMadiuqqpixYoV9OnTh1tuuYUxY8bQv39/RowYwU033VTx9VvLlbYkqc3MnTuXJ554goMPPpiamhrmzp3LsmXLOPvss3njjTe49dZbue666xr6DxkyhMMOOwyAT3/60zz22GMVXWfhwoVMmzaNb37zm9s1vscff5xFixZx2GGHUVNTw6xZs3jhhcZf+52ZjfZFBBs2bOCWW27hySef5KWXXqK6upqrrrpqu8bQGq60Jak7amZF3F4yk8mTJzcKsrVr11JXVwfAm2++yS677AI0fpo6IvjNb37DueeeC8CVV15JdXX1Zn3q6uo45ZRT+M53vsN+++0HwA9/+EOuuOIKAG677TZqa2u3Or7x48dz9913b7Z/y2tWVVXx6KOPbnbNo446igWluxebrnvqqafyta99rYKZaRuGtiSpzRx77LGcfPLJXHTRRQwePJg1a9bwxhtvcN1113HGGWew77778rnPfY5//ud/BuCPf/wjv/71rzn00EO5++67Ofzwwxk3blxDOEL90+ObvPbaa3zkIx/hqquualihA5xyyimccsopzY7vkEMO4fzzz2fp0qUMHz684ZeJLa+5Zs0a/v7v/55XX30VqP8c/KqrrmLdunUsWrSIlStXMmjQIB555BFGjhzZ2mmrmKEtSWozo0aNYsaMGRx//PG899579OnTh5kzZzJv3jx+9atf0atXL+6//37uuOMOjj76aEaOHMmsWbM499xzGTFiBJ///Oe3ef4bb7yRpUuXMn36dKZPnw7UB+rgwYMb9R06dCivv/4669ev50c/+hEPP/wwo0aN4s477+T0009veIBtxowZfPCDH9zs2AEDBvAP//APHHzwwQBcdtllDBgwAIB//Md/5Mgjj6RPnz7su+++3Hnnna2dtopFU/ftO1NtbW1aT1uStt+zzz7boau+1lq+fDkf/ehHW/RPsoqsqb+niHgiM5u+p1/GB9EkSSoIQ1uS1CmGDh3a41bZrWVoS5JUEIa2JEkFYWhLklQQhrYkSQVhaEuSujRLc/6ZX64iSSoMS3NKktSGLM3ZfgxtSequjjqq8c/NN9e3rV3bdPumr+RctapxWwXKS3MuWLCAXr16bVaa8/rrr28ozQmwePFizjnnHJ566il23XVXbt40vgq0tjTn7373O2pra5k5c2ajfpWU5txrr71YtGgRZ511VsXXb62KQjsiJkTE4ohYGhGXNtF+XkQ8HRELIuKxiBi1Rfs+EfFmRFRWJFWSVEiW5mxfzX6mHRG9gJuA8UAdMC8iHsjMRWXdvp+Zt5b6TwRmAhPK2v8J+GmbjVqS1Lyy0pKN7LTTttsHDtx2+1ZYmrN9VfIg2lhgaWYuA4iI2cDJQENoZ+brZf37Aw2/okTEx4BlwFttMWBJUtdlac72VUlo7w28WLZdB4zbslNEnA9cDPQFjint6w9Mo36VvtVb4xFxDnAOwD777FPh0CVJXY2lOdtXs6U5I+ITwAmZeXZp+zPA2Mz8H1vp/6lS/8kRcR3w28y8JyIuB97MzOuaOm4TS3NKUstYmrMYWlOas5KVdh0wpGy7CnhpG/1nA7eUXo8DJkXENcBuwHsRsS4zb6zgupIkqUwloT0PGBERw4AVwGnAp8o7RMSIzFxS2vwIsAQgM48o63M59SttA1uSZGnOFmg2tDNzY0RcAMwBegHfzsyFEXElMD8zHwAuiIjjgA3Aq8Dk9hy0JEk9UUVfY5qZDwIPbrHvsrLXX6jgHJdv7+AkSdKf+Y1okiQVhKEtSVJBGNqSpC6ts0pzTpgwgd12242PfvSjm+0/44wz+NCHPsT+++/PlClT2LBhQ4vO3xKGtiSpMDaV5nz66aeZNWsWn/nMZ5rst6k0Z/n3nG+vL37xi9x1112N9p9xxhn84Q9/4Omnn+btt9/mtttua/E1tpehLUlqU92hNCfUfyXrpu9IL3fSSScREUQEY8eObfhO9Y5Q0dPjkqRiufChC1nwXwua77gdavas4YYJN2yzT3lpzj59+jB16tTNSnOOGzeuoTTn8uXLWbx4MbfffjuHHXYYU6ZM4eabb+aSSyorCNna0pz9+/fn6quvZubMmVx22WXNH7yFDRs2cNddd/H1r399u49tKUNbktRmyktzArz99tsMHjyYyy+/nHvvvZdbb711s8IcW5bm/MY3vlFRaG8qzfnwww9v1/jKS3MCrF+/nkMPPXS7zrHJ1KlTOfLIIzniiCOa79xGDG1J6oaaWxG3l+5SmnPixInbfJ9XXHEFK1eu3O563q1laEuS2kx3Kc25Lbfddhtz5sxh7ty57LBDxz4a5oNokqQ2U16as7q6mvHjx7N8+XLmzZvHtGnTOOOMM+jbty933HEHQENpzurqatasWbNdpTlramqoqanhlVdeabLv0KFDufjii7nzzjupqqpi0aJFDBo0qKE0Z3V1NYcccgh/+MMfmjz+iCOO4BOf+ARz586lqqqKOXPmAHDeeefx8ssvc+ihh1JTU8OVV17ZihnbPs2W5uxoluaUpJaxNGcxtKY0pyttSZIKwtCWJHUKS3NuP0NbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5LUpVma888MbUlSYViaU5KkNmRpzvbjd49LUjd11J1HNdp36uhTmXrwVNZuWMtJ3zupUfuZNWdyZs2ZrFq7ikn3TNqs7dEzH232mpbmbF+GtiSpzVias30Z2pLUTW1rZbxTn5222T5wp4EVray3ZGnO9mVoS5LajKU525cPokmS2oylOduXpTklqZuwNGcxWJpTkqQewNCWJHUKS3NuP0NbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5LUpbWkNCfAVVddxfDhw/nQhz7U8G+st/T8888zbtw4RowYwSc/+UnWr18PwDvvvMMnP/lJhg8fzrhx4zb7gpetnXfKlCkMHjy4YaztwdCWJBVGpaU5Fy1axOzZs1m4cCEPPfQQU6dO5d13323Ub9q0aVx00UUsWbKE3Xffndtvvx2A22+/nd13352lS5dy0UUXMW3atGbPe+aZZ/LQQw+10zuvZ2hLktpUVyjN+eMf/5jTTjuNHXfckWHDhjF8+HB++9vfbtYnM/n5z3/OpEn11cwmT57Mj370o4bjJ0+eDMCkSZOYO3cumbnN8x555JEMGDCgdZPXDL97XJK6oQsvhAq/SrtiNTVwww3b7tNVSnOuWLGCQw45pGG7qqqKFStWbNZn9erV7LbbbvTu3btRnxUrVjBkyBAAevfuzfve9z5Wr15d0XnbkyttSVKbKS/NWVNTw9y5c1m2bBlnn302b7zxBrfeeivXXXddQ/8tS3M+9thjFV1nU2nOrVXZauoruresKLatPltrq+S87cmVtiR1Q82tiNtLVynNWVVVxYsvvrjZMZtuq28ycOBAXnvtNTZu3Ejv3r0367Pp+KqqKjZu3Mif/vQnBgwYUNF525MrbUlSmzn22GO57777GipvrVmzhhdeeKGhwteVV17J5z73uYb+m0pzAo1Kcy5YsKBRXettlebcdExtbS0TJ05k9uzZvPPOOzz//PMsWbKEsWPHbnauiODoo4/mvvvuA2DWrFmcfPLJAEycOJFZs2YBcN9993HMMccQERWdt11lZpf6Oeigg1KStP0WLVrU2UPIzMzZs2fnhz/84RwzZkweeOCB+eijj+a4ceNy48aNmZl5yimn5Le//e18/vnnc+TIkXnuuefmmDFj8uMf/3i+9dZbjc73/PPP5+jRozMzc/r06bnTTjvlhz/84Yafl19+uclxzJgxIz/wgQ/kBz/4wXzwwQcb9p944om5YsWKzMx87rnn8uCDD8799tsvJ02alOvWrcvMzLfffjsnTZqU++23Xx588MH53HPPNXve0047Lffcc8/s3bt37r333nnbbbc1Oa6m/p6A+VlBRlqaU5K6CUtzFoOlOSVJ6gEMbUlSp7A05/YztCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSV2apTn/rKLQjogJEbE4IpZGxKVNtJ8XEU9HxIKIeCwiRpX2j4+IJ0ptT0TEMW39BiRJPYelOZsREb2Am4ATgVHA6ZtCucz3M3NMZtYA1wAzS/tXAX+TmWOAycBdbTZySVKXZGnO9lPJSnsssDQzl2XmemA2cHJ5h8x8vWyzP5Cl/U9m5kul/QuBfhHRuIaaJKnNHXVU45+bb65vW7u26fY776xvX7WqcVslyktzLliwgF69em1WmvP6669vKM0JsHjxYs455xyeeuopdt11V27eNMAKNFeac1NpTWjb0pzNnbc9VRLaewMvlm3XlfZtJiLOj4jnqF9p/88mzvO3wJOZ2fhXIklSt2BpzvZVSWnOpkbTaNSZeRNwU0R8Cvgq9bfD608QMRq4Gji+yQtEnAOcA7DPPvtUMCRJUnMefXTrbTvttO32gQO33b41aWnOdlXJSrsOGFK2XQW8tJW+UH/7/GObNiKiCvgh8NnMfK6pAzLzW5lZm5m1gwYNqmBIkqSuyNKc7ay5MmDUr8aXAcOAvsDvgdFb9BlR9vpvKJUYA3Yr9f/bSkqOpaU5JanFLM25uR5bmjMiTgJuAHoB387M/xURV5Yu8kBEfB04DtgAvApckJkLI+KrwJeBJWWnOz4zX9natSzNKUktY2nOYmhNac5KPtMmMx8EHtxi32Vlr7+wleNmADMquYYkSdo2vxFNktQpLM25/QxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUlSl9YZpTn/9V//lQMPPJDevXs3fPlKV2BoS5IKo6NKc+6zzz7ceeedfOpTn2rX97O9DG1JUpvqDqU5hw4dSnV1NTvs0LVisqIvV5EkFcuSJRfy5psL2vScO+9cw4gRN2yzT3lpzj59+jB16tTNSnOOGzeuoTTn8uXLWbx4MbfffjuHHXYYU6ZM4eabb+aSSy6paDzNleY85JBDGra3tzRnV9W1foWQJBVadynN2VW50pakbqi5FXF7yW5SmrOrcqUtSWoz3aU0Z1dlaEuS2syoUaOYMWMGxx9/PNXV1YwfP57ly5czb968huDu27cvd9xxBwAjR45k1qxZVFdXs2bNGj7/+c9v8/w33ngjS5cuZfr06dTU1FBTU9PwC0K50aNHc+qppzJq1CgmTJjATTfdRK9evQA46aSTeOmllwC4+uqrmTlzJsOHD2f16tWcddZZAMybN4+qqiruvfdezj33XEaPHt2W09RiFZXm7EiW5pSklrE0ZzG0pjSnK21JkgrC0JYkdQpLc24/Q1uSpIIwtCVJKghDW5KkgjC0JUkqCENbktSlWZrzzwxtSVJhWJpTkqQ2ZGnO9mPBEEnqpp588qhG+wYPPpW9957Ku++u5amnTmrUvueeZ/L+95/J+vWrWLhw0mZtBxzwaLPXtDRn++pav0JIkgrN0pzty5W2JHVT21oZ9+q10zbb+/YdWNHKekuW5mxfrrQlSW3G0pzty9CWJLUZS3O2L0tzSlI3YWnOYrA0pyRJPYChLUnqFJbm3H6GtiRJBWFoS1I30tWeU9LmWvv3Y2hLUjfRr18/Vq9ebXB3UZnJ6tWr6devX4vP4ZerSFI3UVVVRV1dHStXruzsoWgr+vXrR1VVVYuPN7QlqZvo06cPw4YN6+xhqB15e1ySpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSSoIQ1uSpIKoKLQjYkJELI6IpRFxaRPt50XE0xGxICIei4hRZW1fLh23OCJOaMvBS5LUkzQb2hHRC7gJOBEYBZxeHsol38/MMZlZA1wDzCwdOwo4DRgNTABuLp1PkiRtp0pW2mOBpZm5LDPXA7OBk8s7ZObrZZv9gSy9PhmYnZnvZObzwNLS+SRJ0nbqXUGfvYEXy7brgHFbdoqI84GLgb7AMWXHPr7FsXs3cew5wDkA++yzTyXjliSpx6lkpR1N7MtGOzJvysz9gGnAV7fz2G9lZm1m1g4aNKiCIUmS1PNUEtp1wJCy7SrgpW30nw18rIXHSpKkragktOcBIyJiWET0pf7BsgfKO0TEiLLNjwBLSq8fAE6LiB0jYhgwAvht64ctSVLP0+xn2pm5MSIuAOYAvYBvZ+bCiLgSmJ+ZDwAXRMRxwAbgVWBy6diFEXEPsAjYCJyfme+203uRJKlbi8xGHzF3qtra2pw/f35nD0OSpA4TEU9kZm1z/fxGNEmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAqCu2ImBARiyNiaURc2kT7xRGxKCKeioi5EbFvWds1EbEwIp6NiG9ERLTlG5AkqadoNrQjohdwE3AiMAo4PSJGbdHtSaA2M6uB+4BrSsf+N+AwoBrYHzgY+Os2G70kST1IJSvtscDSzFyWmeuB2cDJ5R0y8xeZuba0+ThQtakJ6Af0BXYE+gAvt8XAJUnqaSoJ7b2BF8u260r7tuYs4KcAmflr4BfAf5Z+5mTmsy0bqiRJPVslod3UZ9DZZMeITwO1wLWl7eHASOpX3nsDx0TEkU0cd05EzI+I+StXrqx07JIk9SiVhHYdMKRsuwp4actOEXEc8BVgYma+U9p9CvB4Zr6ZmW9SvwI/ZMtjM/NbmVmbmbWDBg3a3vcgSVKPUElozwNGRMSwiOgLnAY8UN4hIg4Avkl9YL9S1vRH4K8jondE9KH+ITRvj0uS1ALNhnZmbgQuAOZQH7j3ZObCiLgyIiaWul0L7AzcGxELImJTqN8HPAc8Dfwe+H1m/qSt34QkST1BZDb58XSnqa2tzfnz53f2MCRJ6jAR8URm1jbXz29EkySpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpIAxtSZIKwtCWJKkgDG1JkgrC0JYkqSAMbUmSCsLQliSpICoK7YiYEBGLI2JpRFzaRPvFEbEoIp6KiLkRsW9Z2z4R8XBEPFvqM7Tthi9JUs/RbGhHRC/gJuBEYBRwekSM2qLbk0BtZlYD9wHXlLV9B7g2M0cCY4FX2mLgkiT1NJWstMcCSzNzWWauB2YDJ5d3yMxfZOba0ubjQBVAKdx7Z+YjpX5vlvWTJEnboZLQ3ht4sWy7rrRva84Cflp6/UHgtYj4fxHxZERcW1q5byYizomI+RExf+XKlZWOXZKkHqWS0I4m9mWTHSM+DdQC15Z29QaOAC4BDgY+AJzZ6GSZ38rM2sysHTRoUAVDkiSp56kktOuAIWXbVcBLW3aKiOOArwATM/OdsmOfLN1a3wj8CDiwdUOWJKlnqiS05wEjImJYRPQFTgMeKO8QEQcA36Q+sF/Z4tjdI2LT8vkYYFHrhy1JUs/TbGiXVsgXAHOAZ4F7MnNhRFwZERNL3a4FdgbujYgFEfFA6dh3qb81Pjcinqb+Vvv/bYf3IUlStxeZTX483Wlqa2tz/vz5nT0MSZI6TEQ8kZm1zfXzG9EkSSoIQ1uSpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCMLQlSSoIQ1uSpIIwtCVJKghDW5KkgjC0JUkqCENbkqSCqCi0I2JCRCyOiKURcWkT7RdHxKKIeCoi5kbEvlu07xoRKyLixrYauCRJPU2zoR0RvYCbgBOBUcDpETFqi25PArWZWQ3cB1yzRft04JetH64kST1XJSvtscDSzFyWmeuB2cDJ5R0y8xeZuba0+ThQtaktIg4C/hJ4uG2GLElSz1RJaO8NvFi2XVfatzVnAT8FiIgdgOuBL27rAhFxTkTMj4j5K1eurGBIkiT1PJWEdjSxL5vsGPFpoBa4trRrKvBgZr7YVP+Gk2V+KzNrM7N20KBBFQxJkqSep3cFfeqAIWXbVcBLW3aKiOOArwB/nZnvlHYfChwREVOBnYG+EfFmZjZ6mE2SJG1bJaE9DxgREcOAFcBpwKfKO0TzeIXTAAAEz0lEQVTEAcA3gQmZ+cqm/Zl5RlmfM6l/WM3AliSpBZq9PZ6ZG4ELgDnAs8A9mbkwIq6MiImlbtdSv5K+NyIWRMQD7TZiSZJ6qMhs8uPpTlNbW5vz58/v7GFIktRhIuKJzKxtrp/fiCZJUkEY2pIkFUSXuz0eESuBFzp7HB1sILCqswdRcM5h23AeW885bL2eOIf7Zmaz/+a5y4V2TxQR8yv5LENb5xy2Deex9ZzD1nMOt87b45IkFYShLUlSQRjaXcO3OnsA3YBz2Dacx9ZzDlvPOdwKP9OWJKkgXGlLklQQhnYHiYgBEfFIRCwp/bn7VvpNLvVZEhGTm2h/ICKeaf8Rdz2tmcOI2Cki/iUi/hARCyPiax07+s4VERMiYnFELI2IRt//HxE7RsQPSu2/iYihZW1fLu1fHBEndOS4u5KWzmFEjI+IJyLi6dKfx3T02LuS1vy3WGrfJyLejIhLOmrMXUpm+tMBP8A1wKWl15cCVzfRZwCwrPTn7qXXu5e1fxz4PvBMZ7+fos0hsBNwdKlPX+DfgBM7+z110Lz1Ap4DPlB6778HRm3RZypwa+n1acAPSq9HlfrvCAwrnadXZ7+ngs3hAcBepdf7Ays6+/0UcR7L2u8H7gUu6ez30xk/rrQ7zsnArNLrWcDHmuhzAvBIZq7JzFeBR4AJABGxM3AxMKMDxtpVtXgOM3NtZv4CIDPXA7+jvsxsTzAWWJqZy0rvfTb1c1mufG7vA46NiCjtn52Z72Tm88DS0vl6mhbPYWY+mZmbyhkvBPpFxI4dMuqupzX/LRIRH6P+F/GFHTTeLsfQ7jh/mZn/CVD6c3ATffYGXizbrivtA5gOXA+sbc9BdnGtnUMAImI34G+Aue00zq6m2Tkp75P1lf3+BOxR4bE9QWvmsNzfAk9m5jvtNM6ursXzGBH9gWnAFR0wzi6rknraqlBE/AzYs4mmr1R6iib2ZUTUAMMz86ItP9/pbtprDsvO3xu4G/hGZi7b/hEW0jbnpJk+lRzbE7RmDusbI0YDVwPHt+G4iqY183gF8E+Z+WZp4d0jGdptKDOP21pbRLwcEe/PzP+MiPcDrzTRrQ44qmy7CngUOBQ4KCKWU/93NjgiHs3Mo+hm2nEON/kWsCQzb2iD4RZFHTCkbLsKeGkrfepKv9i8D1hT4bE9QWvmkIioAn4IfDYzn2v/4XZZrZnHccCkiLgG2A14LyLWZeaN7T/srsPb4x3nAWDT0+CTgR830WcOcHxE7F56Mvp4YE5m3pKZe2XmUOBw4D+6Y2BXoMVzCBARM6j/H8CFHTDWrmQeMCIihkVEX+of7nlgiz7lczsJ+HnWP/XzAHBa6YneYcAI4LcdNO6upMVzWPo45l+AL2fmrzpsxF1Ti+cxM4/IzKGl/w/eAPzvnhbYgE+Pd9QP9Z9tzQWWlP4cUNpfC9xW1m8K9Q/7LAX+exPnGUrPfXq8xXNI/W/0CTwLLCj9nN3Z76kD5+4k4D+of3L3K6V9VwITS6/7Uf9E7lLqQ/kDZcd+pXTcYnrIE/dtOYfAV4G3yv67WwAM7uz3U7R53OIcl9NDnx73G9EkSSoIb49LklQQhrYkSQVhaEuSVBCGtiRJBWFoS5JUEIa2JEkFYWhLklQQhrYkSQXx/wHhNKLNvdxNOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.ylim([0, 5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
