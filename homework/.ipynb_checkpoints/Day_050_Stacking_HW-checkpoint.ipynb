{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業 : (Kaggle)鐵達尼生存預測\n",
    "***\n",
    "- 分數以網站評分結果為準, 請同學實際將提交檔(*.csv)上傳試試看  \n",
    "https://www.kaggle.com/c/titanic/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [作業目標]\n",
    "- 試著模仿範例寫法, 在鐵達尼生存預測中, 觀查堆疊泛化 (Stacking) 的寫法與效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [作業重點]\n",
    "- 完成堆疊泛化的寫作, 看看提交結果, 想想看 : 分類與回歸的堆疊泛化, 是不是也與混合泛化一樣有所不同呢?(In[14])  \n",
    "如果可能不同, 應該怎麼改寫會有較好的結果?  \n",
    "- Hint : 請參考 mlxtrend 官方網站 StackingClassifier 的頁面說明 : Using Probabilities as Meta-Features\n",
    "http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1      1      0          PC 17599  71.2833   C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      1      0            113803  53.1000  C123        S  \n",
       "4      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 做完特徵工程前的所有準備 (與前範例相同)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy, time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_path = '../data/'\n",
    "df_train = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "df_test = pd.read_csv(data_path + 'titanic_test.csv')\n",
    "\n",
    "train_Y = df_train['Survived']\n",
    "ids = df_test['PassengerId']\n",
    "df_train = df_train.drop(['PassengerId', 'Survived'] , axis=1)\n",
    "df_test = df_test.drop(['PassengerId'] , axis=1)\n",
    "df = pd.concat([df_train,df_test])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>77.463713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>20.091673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.152788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.076394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing Ratio\n",
       "Cabin         77.463713\n",
       "Age           20.091673\n",
       "Embarked       0.152788\n",
       "Fare           0.076394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 檢查 DataFrame 空缺值的狀態\n",
    "def na_check(df_data):\n",
    "    data_na = (df_data.isnull().sum() / len(df_data)) * 100\n",
    "    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "    display(missing_data.head(10))\n",
    "na_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下 In[3]~In[10] 只是鐵達尼預測中的一組特徵工程, 並以此組特徵工程跑參數, 若更換其他特徵工程, In[10]的參數需要重新跑\n",
    "# Sex : 直接轉男 0 女 1\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\":1})\n",
    "# Fare : 用 log 去偏態, 0 則直接取 0\n",
    "df[\"Fare\"] = df[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "# Age : 缺值用中位數補\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title 的 特徵工程 : 將各種頭銜按照類型分類, 最後取 One Hot\n",
    "df_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in df[\"Name\"]]\n",
    "df[\"Title\"] = pd.Series(df_title)\n",
    "df[\"Title\"] = df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "df[\"Title\"] = df[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n",
    "df[\"Title\"] = df[\"Title\"].astype(int)\n",
    "df = pd.get_dummies(df, columns = [\"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建:家庭大小 (Fsize)特徵, 並依照大小分別建獨立欄位\n",
    "df[\"Fsize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "df['Single'] = df['Fsize'].map(lambda s: 1 if s == 1 else 0)\n",
    "df['SmallF'] = df['Fsize'].map(lambda s: 1 if  s == 2  else 0)\n",
    "df['MedF'] = df['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "df['LargeF'] = df['Fsize'].map(lambda s: 1 if s >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket : 如果不只是數字-取第一個空白之前的字串(去除'.'與'/'), 如果只是數字-設為'X', 最後再取 One Hot\n",
    "Ticket = []\n",
    "for i in list(df.Ticket):\n",
    "    if not i.isdigit() :\n",
    "        Ticket.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0])\n",
    "    else:\n",
    "        Ticket.append(\"X\")        \n",
    "df[\"Ticket\"] = Ticket\n",
    "df = pd.get_dummies(df, columns = [\"Ticket\"], prefix=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabib 依照第一碼分類, 再取 One Hot\n",
    "df[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in df['Cabin'] ])\n",
    "df = pd.get_dummies(df, columns = [\"Cabin\"], prefix=\"Cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked, Pclass 取 One Hot\n",
    "df = pd.get_dummies(df, columns = [\"Embarked\"], prefix=\"Em\")\n",
    "df[\"Pclass\"] = df[\"Pclass\"].astype(\"category\")\n",
    "df = pd.get_dummies(df, columns = [\"Pclass\"], prefix=\"Pc\")\n",
    "\n",
    "# 捨棄 Name 欄位\n",
    "df.drop(labels = [\"Name\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title_0</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Fsize</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Cabin_X</th>\n",
       "      <th>Em_C</th>\n",
       "      <th>Em_Q</th>\n",
       "      <th>Em_S</th>\n",
       "      <th>Pc_1</th>\n",
       "      <th>Pc_2</th>\n",
       "      <th>Pc_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.981001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.266662</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.070022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.972177</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.085672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex   Age  SibSp  Parch      Fare  Title_0  Title_1  Title_2  Title_3  \\\n",
       "0    0  22.0      1      0  1.981001        0        0        1        0   \n",
       "1    1  38.0      1      0  4.266662        0        1        0        0   \n",
       "2    1  26.0      0      0  2.070022        0        1        0        0   \n",
       "3    1  35.0      1      0  3.972177        0        1        0        0   \n",
       "4    0  35.0      0      0  2.085672        0        0        1        0   \n",
       "\n",
       "   Fsize  ...  Cabin_F  Cabin_G  Cabin_T  Cabin_X  Em_C  Em_Q  Em_S  Pc_1  \\\n",
       "0      2  ...        0        0        0        1     0     0     1     0   \n",
       "1      2  ...        0        0        0        0     1     0     0     1   \n",
       "2      1  ...        0        0        0        1     0     0     1     0   \n",
       "3      2  ...        0        0        0        0     0     0     1     1   \n",
       "4      1  ...        0        0        0        1     0     0     1     0   \n",
       "\n",
       "   Pc_2  Pc_3  \n",
       "0     0     1  \n",
       "1     0     0  \n",
       "2     0     1  \n",
       "3     0     0  \n",
       "4     0     1  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_check(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料最大最小化\n",
    "df = MinMaxScaler().fit_transform(df)\n",
    "\n",
    "# 將前述轉換完畢資料 df , 重新切成 train_X, test_X\n",
    "train_num = train_Y.shape[0]\n",
    "train_X = df[:train_num]\n",
    "test_X = df[train_num:]\n",
    "\n",
    "# 使用三種模型 : 邏輯斯迴歸 / 梯度提升機 / 隨機森林, 參數使用 Random Search 尋找\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "lr = LogisticRegression(tol=0.001, penalty='l2', fit_intercept=True, C=1.0)\n",
    "gdbt = GradientBoostingClassifier(tol=100, subsample=0.75, n_estimators=250, max_features=20,\n",
    "                                  max_depth=6, learning_rate=0.03)\n",
    "rf = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \n",
    "                            max_features='sqrt', max_depth=6, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線性迴歸預測檔 (結果有部分隨機, 請以 Kaggle 計算的得分為準, 以下模型同理)\n",
    "lr.fit(train_X, train_Y)\n",
    "lr_pred = lr.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': lr_pred})\n",
    "sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('titanic_lr.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度提升機預測檔 \n",
    "gdbt.fit(train_X, train_Y)\n",
    "gdbt_pred = gdbt.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': gdbt_pred})\n",
    "sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('titanic_gdbt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機森林預測檔\n",
    "rf.fit(train_X, train_Y)\n",
    "rf_pred = rf.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': rf_pred})\n",
    "sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('titanic_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業\n",
    "* 分類預測的集成泛化, 也與回歸的很不一樣  \n",
    "既然分類的 Blending 要變成機率, 才比較容易集成,\n",
    "那麼分類的 Stacking 要讓第一層的模型輸出機率當特徵, 應該要怎麼寫呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "meta_estimator = GradientBoostingClassifier(tol=100, subsample=0.70, n_estimators=50, \n",
    "                                           max_features='sqrt', max_depth=4, learning_rate=0.3)\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "stacking = StackingClassifier(classifiers=[lr_pred,gdbt_pred,rf_pred],meta_classifier=meta_estimator,use_probas = True, average_probas=False)\n",
    "#stacking = StackingRegressor(regressors=[linear, gdbt, rf], meta_regressor=meta_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object 'array([0.08340212, 0.55613262, 0.51722066, 0.42358863, 0.20582838,\n       0.08574485, 0.57523186, 0.81273568, 0.75486179, 0.29563639,\n       0.30794037, 0.71764869, 0.52867297, 0.09034345, 0.74618295,\n       0.8707411 , 0.82933417, 0.11534467, 0.54398364, 0.6705422 ,\n       0.2005181 , 0.29630429, 0.86368801, 0.4639579 , 0.55439105,\n       0.20784934, 0.65092898, 0.15140479, 0.66888451, 0.10934534,\n       0.18057656, 0.77329309, 0.61256251, 0.09628687, 0.3188428 ,\n       0.1193255 , 0.19393324, 0.21359196, 0.3551398 , 0.42456065,\n       0.37733557, 0.70601994, 0.0633258 , 0.81499054, 0.83558462,\n       0.29531923, 0.25743243, 0.40951282, 0.5789232 , 0.62105185,\n       0.86321053, 0.25567982, 0.93488358, 0.52347266, 0.43879016,\n       0.01986074, 0.31325346, 0.07103334, 0.3006215 , 0.9749136 ,\n       0.08000609, 0.74871765, 0.10673938, 0.87652636, 0.08133186,\n       0.954442  , 0.83002346, 0.22104243, 0.79034589, 0.09949577,\n       0.25819962, 0.36116651, 0.19108811, 0.30587617, 0.70996505,\n       0.58992975, 0.06867362, 0.38790272, 0.79447692, 0.70639523,\n       0.1463632 , 0.14183415, 0.63417875, 0.06843917, 0.64776174,\n       0.40573201, 0.25007645, 0.16520781, 0.76010558, 0.23265402,\n       0.17785693, 0.06825281, 0.77935622, 0.06867362, 0.37005959,\n       0.07127019, 0.48544033, 0.55417529, 0.65172188, 0.05623545,\n       0.89564311, 0.14710411, 0.24036197, 0.07022888, 0.3005512 ,\n       0.15521796, 0.43611866, 0.09118367, 0.06964004, 0.61691997,\n       0.27804092, 0.69366848, 0.56794454, 0.72121096, 0.79851978,\n       0.10325174, 0.10279896, 0.36540493, 0.57839952, 0.81163034,\n       0.46879939, 0.06905939, 0.5858504 , 0.6812939 , 0.24036197,\n       0.83512694, 0.07437538, 0.25548672, 0.67456742, 0.07270128,\n       0.06630799, 0.28012748, 0.19547066, 0.36930985, 0.05515382,\n       0.07238679, 0.72317372, 0.22528377, 0.22605912, 0.01736202,\n       0.17807458, 0.9099252 , 0.23803563, 0.1868108 , 0.21894862,\n       0.05771651, 0.28291383, 0.34889781, 0.39068514, 0.24330561,\n       0.75553596, 0.5354877 , 0.02927092, 0.18198365, 0.0094723 ,\n       0.03007115, 0.90027804, 0.20543471, 0.21894862, 0.85522608,\n       0.24655246, 0.5385585 , 0.40563839, 0.06699607, 0.7655718 ,\n       0.84349069, 0.91546262, 0.03335522, 0.64949048, 0.21210599,\n       0.06181058, 0.70181804, 0.3109736 , 0.10484752, 0.01440618,\n       0.48842422, 0.94777003, 0.75678392, 0.39279668, 0.49826341,\n       0.5744859 , 0.30171793, 0.95662834, 0.78561462, 0.93321289,\n       0.24984497, 0.63594822, 0.04979936, 0.01701588, 0.14351098,\n       0.51710998, 0.25709364, 0.3673572 , 0.85754001, 0.83092615,\n       0.51494946, 0.50924945, 0.21790265, 0.59389967, 0.62483062,\n       0.27188169, 0.10842475, 0.26786707, 0.4801325 , 0.17025214,\n       0.71635595, 0.22723345, 0.17056046, 0.90268457, 0.1281579 ,\n       0.14734524, 0.35850861, 0.1712338 , 0.2533432 , 0.01605614,\n       0.86981951, 0.69418346, 0.22217881, 0.97464795, 0.06867362,\n       0.43798116, 0.07586374, 0.22780792, 0.07543781, 0.57987049,\n       0.29847497, 0.07332674, 0.24662853, 0.06498916, 0.55185921,\n       0.76632075, 0.55792873, 0.05506492, 0.41027197, 0.24915407,\n       0.36447916, 0.2261575 , 0.47785103, 0.40989236, 0.50438838,\n       0.89436498, 0.79854291, 0.34875833, 0.06842644, 0.03162192,\n       0.34752906, 0.8891595 , 0.54791616, 0.63251056, 0.339042  ,\n       0.49681668, 0.31361846, 0.44700605, 0.07460543, 0.32926484,\n       0.33783016, 0.41526467, 0.535229  , 0.83908307, 0.36049153,\n       0.05249028, 0.61789913, 0.74882396, 0.44650687, 0.68839548,\n       0.06843917, 0.15714755, 0.06873622, 0.7045412 , 0.46139228,\n       0.34248937, 0.09118367, 0.92968042, 0.27880199, 0.44736824,\n       0.93177484, 0.60044227, 0.12381239, 0.76030483, 0.38460794,\n       0.20848655, 0.11224038, 0.24662853, 0.34823227, 0.42517586,\n       0.05284024, 0.0751726 , 0.25291864, 0.10484752, 0.30780909,\n       0.66951943, 0.82925741, 0.26974517, 0.64764279, 0.06306421,\n       0.07042022, 0.55061332, 0.54301537, 0.34323364, 0.53024892,\n       0.32259245, 0.25133022, 0.05238329, 0.70158189, 0.24662853,\n       0.94254002, 0.73320821, 0.46736436, 0.20915674, 0.81848121,\n       0.45758446, 0.66725353, 0.34034306, 0.22189399, 0.5642005 ,\n       0.73274437, 0.66617922, 0.26110489, 0.41905512, 0.86945039,\n       0.07022888, 0.10924357, 0.58940481, 0.68986144, 0.5867553 ,\n       0.45796519, 0.45147433, 0.89965153, 0.5362181 , 0.77786583,\n       0.79945493, 0.34734762, 0.14088592, 0.31560102, 0.34022388,\n       0.25128068, 0.20963484, 0.73873019, 0.20176583, 0.1368991 ,\n       0.89296973, 0.39889319, 0.0082101 , 0.55628773, 0.06123555,\n       0.78510479, 0.58940481, 0.69382706, 0.81019561, 0.50272722,\n       0.50716316, 0.29429313, 0.16906895, 0.14380172, 0.27451357,\n       0.19806481, 0.95263033, 0.33670153, 0.40951282, 0.57468448,\n       0.00648308, 0.55802645, 0.82801512, 0.07056829, 0.6206749 ,\n       0.02629948, 0.68286886, 0.71166231, 0.89986345, 0.83668085,\n       0.40931308, 0.70487359, 0.11903728, 0.13613636, 0.85519654,\n       0.92201802, 0.61137957, 0.23473781, 0.20571346, 0.01069517,\n       0.40951282, 0.41771097, 0.21199472, 0.6168596 , 0.16847565,\n       0.44567166, 0.60652316, 0.47158407, 0.10047632, 0.07679339,\n       0.51838952, 0.34599615, 0.09767568, 0.76146233, 0.04911924,\n       0.53284365, 0.42133107, 0.60146284, 0.11333851, 0.39834034,\n       0.60859687, 0.12274474, 0.92746219, 0.31438745, 0.6975281 ,\n       0.27356441, 0.13373973, 0.91451099, 0.24649542, 0.73367023,\n       0.24662853, 0.55784279, 0.69818772, 0.06044517, 0.61345708,\n       0.32354695, 0.33761132, 0.47633091])' (type <type 'numpy.ndarray'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-48a2d56a20ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstacking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstacking_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'PassengerId'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Survived'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstacking_pred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titanic_stacking.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ian/anaconda2/lib/python2.7/site-packages/mlxtend/classifier/stacking_classification.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_clones\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclfs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_clf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ian/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ian/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     58\u001b[0m                             \u001b[0;34m\"it does not seem to be a scikit-learn estimator \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                             \u001b[0;34m\"as it does not implement a 'get_params' methods.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                             % (repr(estimator), type(estimator)))\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object 'array([0.08340212, 0.55613262, 0.51722066, 0.42358863, 0.20582838,\n       0.08574485, 0.57523186, 0.81273568, 0.75486179, 0.29563639,\n       0.30794037, 0.71764869, 0.52867297, 0.09034345, 0.74618295,\n       0.8707411 , 0.82933417, 0.11534467, 0.54398364, 0.6705422 ,\n       0.2005181 , 0.29630429, 0.86368801, 0.4639579 , 0.55439105,\n       0.20784934, 0.65092898, 0.15140479, 0.66888451, 0.10934534,\n       0.18057656, 0.77329309, 0.61256251, 0.09628687, 0.3188428 ,\n       0.1193255 , 0.19393324, 0.21359196, 0.3551398 , 0.42456065,\n       0.37733557, 0.70601994, 0.0633258 , 0.81499054, 0.83558462,\n       0.29531923, 0.25743243, 0.40951282, 0.5789232 , 0.62105185,\n       0.86321053, 0.25567982, 0.93488358, 0.52347266, 0.43879016,\n       0.01986074, 0.31325346, 0.07103334, 0.3006215 , 0.9749136 ,\n       0.08000609, 0.74871765, 0.10673938, 0.87652636, 0.08133186,\n       0.954442  , 0.83002346, 0.22104243, 0.79034589, 0.09949577,\n       0.25819962, 0.36116651, 0.19108811, 0.30587617, 0.70996505,\n       0.58992975, 0.06867362, 0.38790272, 0.79447692, 0.70639523,\n       0.1463632 , 0.14183415, 0.63417875, 0.06843917, 0.64776174,\n       0.40573201, 0.25007645, 0.16520781, 0.76010558, 0.23265402,\n       0.17785693, 0.06825281, 0.77935622, 0.06867362, 0.37005959,\n       0.07127019, 0.48544033, 0.55417529, 0.65172188, 0.05623545,\n       0.89564311, 0.14710411, 0.24036197, 0.07022888, 0.3005512 ,\n       0.15521796, 0.43611866, 0.09118367, 0.06964004, 0.61691997,\n       0.27804092, 0.69366848, 0.56794454, 0.72121096, 0.79851978,\n       0.10325174, 0.10279896, 0.36540493, 0.57839952, 0.81163034,\n       0.46879939, 0.06905939, 0.5858504 , 0.6812939 , 0.24036197,\n       0.83512694, 0.07437538, 0.25548672, 0.67456742, 0.07270128,\n       0.06630799, 0.28012748, 0.19547066, 0.36930985, 0.05515382,\n       0.07238679, 0.72317372, 0.22528377, 0.22605912, 0.01736202,\n       0.17807458, 0.9099252 , 0.23803563, 0.1868108 , 0.21894862,\n       0.05771651, 0.28291383, 0.34889781, 0.39068514, 0.24330561,\n       0.75553596, 0.5354877 , 0.02927092, 0.18198365, 0.0094723 ,\n       0.03007115, 0.90027804, 0.20543471, 0.21894862, 0.85522608,\n       0.24655246, 0.5385585 , 0.40563839, 0.06699607, 0.7655718 ,\n       0.84349069, 0.91546262, 0.03335522, 0.64949048, 0.21210599,\n       0.06181058, 0.70181804, 0.3109736 , 0.10484752, 0.01440618,\n       0.48842422, 0.94777003, 0.75678392, 0.39279668, 0.49826341,\n       0.5744859 , 0.30171793, 0.95662834, 0.78561462, 0.93321289,\n       0.24984497, 0.63594822, 0.04979936, 0.01701588, 0.14351098,\n       0.51710998, 0.25709364, 0.3673572 , 0.85754001, 0.83092615,\n       0.51494946, 0.50924945, 0.21790265, 0.59389967, 0.62483062,\n       0.27188169, 0.10842475, 0.26786707, 0.4801325 , 0.17025214,\n       0.71635595, 0.22723345, 0.17056046, 0.90268457, 0.1281579 ,\n       0.14734524, 0.35850861, 0.1712338 , 0.2533432 , 0.01605614,\n       0.86981951, 0.69418346, 0.22217881, 0.97464795, 0.06867362,\n       0.43798116, 0.07586374, 0.22780792, 0.07543781, 0.57987049,\n       0.29847497, 0.07332674, 0.24662853, 0.06498916, 0.55185921,\n       0.76632075, 0.55792873, 0.05506492, 0.41027197, 0.24915407,\n       0.36447916, 0.2261575 , 0.47785103, 0.40989236, 0.50438838,\n       0.89436498, 0.79854291, 0.34875833, 0.06842644, 0.03162192,\n       0.34752906, 0.8891595 , 0.54791616, 0.63251056, 0.339042  ,\n       0.49681668, 0.31361846, 0.44700605, 0.07460543, 0.32926484,\n       0.33783016, 0.41526467, 0.535229  , 0.83908307, 0.36049153,\n       0.05249028, 0.61789913, 0.74882396, 0.44650687, 0.68839548,\n       0.06843917, 0.15714755, 0.06873622, 0.7045412 , 0.46139228,\n       0.34248937, 0.09118367, 0.92968042, 0.27880199, 0.44736824,\n       0.93177484, 0.60044227, 0.12381239, 0.76030483, 0.38460794,\n       0.20848655, 0.11224038, 0.24662853, 0.34823227, 0.42517586,\n       0.05284024, 0.0751726 , 0.25291864, 0.10484752, 0.30780909,\n       0.66951943, 0.82925741, 0.26974517, 0.64764279, 0.06306421,\n       0.07042022, 0.55061332, 0.54301537, 0.34323364, 0.53024892,\n       0.32259245, 0.25133022, 0.05238329, 0.70158189, 0.24662853,\n       0.94254002, 0.73320821, 0.46736436, 0.20915674, 0.81848121,\n       0.45758446, 0.66725353, 0.34034306, 0.22189399, 0.5642005 ,\n       0.73274437, 0.66617922, 0.26110489, 0.41905512, 0.86945039,\n       0.07022888, 0.10924357, 0.58940481, 0.68986144, 0.5867553 ,\n       0.45796519, 0.45147433, 0.89965153, 0.5362181 , 0.77786583,\n       0.79945493, 0.34734762, 0.14088592, 0.31560102, 0.34022388,\n       0.25128068, 0.20963484, 0.73873019, 0.20176583, 0.1368991 ,\n       0.89296973, 0.39889319, 0.0082101 , 0.55628773, 0.06123555,\n       0.78510479, 0.58940481, 0.69382706, 0.81019561, 0.50272722,\n       0.50716316, 0.29429313, 0.16906895, 0.14380172, 0.27451357,\n       0.19806481, 0.95263033, 0.33670153, 0.40951282, 0.57468448,\n       0.00648308, 0.55802645, 0.82801512, 0.07056829, 0.6206749 ,\n       0.02629948, 0.68286886, 0.71166231, 0.89986345, 0.83668085,\n       0.40931308, 0.70487359, 0.11903728, 0.13613636, 0.85519654,\n       0.92201802, 0.61137957, 0.23473781, 0.20571346, 0.01069517,\n       0.40951282, 0.41771097, 0.21199472, 0.6168596 , 0.16847565,\n       0.44567166, 0.60652316, 0.47158407, 0.10047632, 0.07679339,\n       0.51838952, 0.34599615, 0.09767568, 0.76146233, 0.04911924,\n       0.53284365, 0.42133107, 0.60146284, 0.11333851, 0.39834034,\n       0.60859687, 0.12274474, 0.92746219, 0.31438745, 0.6975281 ,\n       0.27356441, 0.13373973, 0.91451099, 0.24649542, 0.73367023,\n       0.24662853, 0.55784279, 0.69818772, 0.06044517, 0.61345708,\n       0.32354695, 0.33761132, 0.47633091])' (type <type 'numpy.ndarray'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods."
     ]
    }
   ],
   "source": [
    "stacking.fit(train_X, train_Y)\n",
    "stacking_pred = stacking.predict(test_X)\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': stacking_pred})\n",
    "sub.to_csv('titanic_stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
